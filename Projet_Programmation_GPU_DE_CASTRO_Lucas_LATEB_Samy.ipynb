{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Projet Programmation GPU\n",
        "\n",
        "*Par DE CASTRO Lucas et LATEB Samy*\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Dans ce notebook, nous présentons une solution de calcul numérique d'intégrales optimisée en utilisant CUDA (Compute Unified Device Architecture), une plateforme de calcul parallèle développée par NVIDIA. Notre objectif est de tirer parti de la puissance de calcul massive offerte par les GPU, offrant ainsi des gains significatifs en termes de temps d'exécution par rapport aux approches séquentielles traditionnelles sur CPU.\n",
        "\n",
        "Nous élaborerons d'abord une version de notre programme en C++ classique afin de pouvoir le comparer à notre implémentation CUDA par la suite, mais également pour montrer la logique de calcul de nos intégrales."
      ],
      "metadata": {
        "id": "RlYG9sS24wSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prerequis\n",
        "\n",
        "Dans cette partie, nous allons verifier que tous les éléments nécessaires pour utiliser CUDA sont fonctionnels dans ce Notebook Google Colab.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "appO3FeywL2M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vjov-qc1v32O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c260cdae-a3d1-4046-b465-0c826faa0787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2HDpzqSyysu",
        "outputId": "4bc00195-e606-4b98-fd59-e8686c12e827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 15 08:29:00 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic C++ implementation"
      ],
      "metadata": {
        "id": "hmVFfGFiSLyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cpu.cpp\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "\n",
        "// Polynomial definition here\n",
        "double polynomial(double x) {\n",
        "    return x;\n",
        "}\n",
        "\n",
        "// Integration logic using a basic trapeizodial numeric estimation\n",
        "double computeIntegral(double a, double b, int num_intervals) {\n",
        "    double h = (b - a) / num_intervals;\n",
        "    double sum = 0.5 * (polynomial(a) + polynomial(b));\n",
        "\n",
        "    for (int i = 1; i < num_intervals; i++) {\n",
        "        double x = a + i * h;\n",
        "        sum += polynomial(x);\n",
        "    }\n",
        "\n",
        "    return sum * h;\n",
        "}\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "    if (argc < 4) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" <a> <b> <num_interval>\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    double a = std::atof(argv[1]);\n",
        "    double b = std::atof(argv[2]);\n",
        "    int num_intervals = std::atoi(argv[3]);\n",
        "\n",
        "    double integral = computeIntegral(a, b, num_intervals);\n",
        "\n",
        "    std::cout << \"The integral of the polynomial in the range [\" << a << \", \" << b << \"] is: \" << integral << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkGnm4UGSRA7",
        "outputId": "07a3a38d-567f-483f-b778-979a99d97864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cpu.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ -o cpu cpu.cpp"
      ],
      "metadata": {
        "id": "KlntPL7kS1S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile time.sh\n",
        "echo \"Calculating execution time:\"\n",
        "echo \"--------------------------------------\"\n",
        "start=$(date +%s%3N); ./cpu 0 100 100000000000; end=$(date +%s%3N); echo \"Temps d'éxecution: $((end-start)) milliseconds\"\n",
        "echo \"--------------------------------------\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntaWZ9euS7-o",
        "outputId": "05bc976c-84dc-4909-aa8d-ef288c67ec34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting time.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash time.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6WIUBkBwso2",
        "outputId": "8f20b402-ba1f-4d4b-bcea-d27679c77d47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating execution time:\n",
            "--------------------------------------\n",
            "The integral of the polynomial in the range [0, 100] is: 5000\n",
            "Temps d'éxecution: 5043 milliseconds\n",
            "--------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA Implementation"
      ],
      "metadata": {
        "id": "vdZBR7NSxMLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gpu.cu\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "\n",
        "#define TAILLE_BLOC 1024\n",
        "\n",
        "__device__ double polynome(double x) {\n",
        "    return x;\n",
        "}\n",
        "\n",
        "__global__ void calculerIntegral(double a, double b, int num_intervals, double *resultat) {\n",
        "    // Calcule la largeur de chaque sous-intervalle\n",
        "    double h = (b - a) / num_intervals;\n",
        "    // Initialise la somme partielle\n",
        "    double somme = 0.5 * (polynome(a) + polynome(b));\n",
        "\n",
        "    // Calcule l'index global du thread\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int pas = blockDim.x * gridDim.x;\n",
        "\n",
        "    // Initialise la somme partielle du bloc\n",
        "    double somme_partielle = 0.0;\n",
        "    for (int i = idx; i < num_intervals; i += pas) {\n",
        "        double x = a + (i + 0.5) * h;\n",
        "        somme_partielle += polynome(x);\n",
        "    }\n",
        "\n",
        "    // Réduction dans le bloc\n",
        "    __shared__ double memoire_partagee[TAILLE_BLOC];\n",
        "    memoire_partagee[threadIdx.x] = somme_partielle;\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1) {\n",
        "        if (threadIdx.x < stride) {\n",
        "            memoire_partagee[threadIdx.x] += memoire_partagee[threadIdx.x + stride];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (threadIdx.x == 0) {\n",
        "        // Échelle pour l'opération atomique atomicCAS\n",
        "        unsigned long long int* adresse_comme_i = reinterpret_cast<unsigned long long int*>(resultat);\n",
        "        unsigned long long int ancienne_valeur = *adresse_comme_i;\n",
        "        unsigned long long int nouvelle_valeur;\n",
        "        do {\n",
        "            ancienne_valeur = *adresse_comme_i;\n",
        "            nouvelle_valeur = __double_as_longlong(__longlong_as_double(ancienne_valeur) + memoire_partagee[0] * h);\n",
        "        } while (atomicCAS(adresse_comme_i, ancienne_valeur, nouvelle_valeur) != ancienne_valeur);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(int argc, char* argv[]) {\n",
        "    if (argc < 4) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" <a> <b> <num_intervalles>\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    double a = std::atof(argv[1]);\n",
        "    double b = std::atof(argv[2]);\n",
        "    int num_intervalles = std::atoi(argv[3]);\n",
        "    double integral = 0.0;\n",
        "\n",
        "    double *d_resultat;\n",
        "    cudaMalloc(&d_resultat, sizeof(double));\n",
        "    cudaMemcpy(d_resultat, &integral, sizeof(double), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int numThreads = TAILLE_BLOC;\n",
        "    int numBlocs = (num_intervalles + numThreads - 1) / numThreads;\n",
        "    calculerIntegral<<<numBlocs, numThreads>>>(a, b, num_intervalles, d_resultat);\n",
        "\n",
        "    cudaError_t cuda_error = cudaGetLastError();\n",
        "    if (cuda_error != cudaSuccess) {\n",
        "        std::cerr << \"Erreur de lancement du noyau CUDA: \" << cudaGetErrorString(cuda_error) << std::endl;\n",
        "        cudaFree(d_resultat);\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(&integral, d_resultat, sizeof(double), cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d_resultat);\n",
        "\n",
        "    std::cout << \"L'intégrale du polynôme dans l'intervalle [\" << a << \", \" << b << \"] est: \" << integral << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KssMuanhxSgC",
        "outputId": "882e8f27-2e0e-4f75-be32-ae35d6c9e2d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting gpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o gpu gpu.cu"
      ],
      "metadata": {
        "id": "YwdrvKxwxyqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile time.sh\n",
        "echo \"Calculating execution time:\"\n",
        "echo \"--------------------------------------\"\n",
        "start=$(date +%s%3N); ./gpu 0 100 100000000000; end=$(date +%s%3N); echo \"Temps d'éxecution: $((end-start)) milliseconds\"\n",
        "echo \"--------------------------------------\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRkHEjrlxoGF",
        "outputId": "ee651906-0902-4b56-8ef5-0783c5cfe327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting time.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash time.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdvDCTgLxofC",
        "outputId": "c0743058-7930-42e2-aa3d-19421dbde0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating execution time:\n",
            "--------------------------------------\n",
            "L'intégrale du polynôme dans l'intervalle [0, 100] est: 5000\n",
            "Temps d'éxecution: 654 milliseconds\n",
            "--------------------------------------\n"
          ]
        }
      ]
    }
  ]
}